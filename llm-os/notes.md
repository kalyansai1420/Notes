# LLM-OS

## Initial findings

- LLM has two files (ex. llama-2-70b)
  - what is llama-2-70b all about
    - model architecture
    - weights
    - paper released by meta
  - parameters
    - weights of neural networks
    - every parameter 2 bytes
    - 140gb
  - run.c
    - ~500lines of C code
- How to obtain parameters ( llama-2-70b )
  - first step
    - get text from internet ~10TB
  - next step 
    - 6000 GPUs for 12 days
    - cost around $2M
  - next step
    - parameters.zip
    - ~140GB file
- Neural Networks
  - Predicts the next word in the sequence
- How does it work ?
  - transform NN architecture
  - little is known in full detail
    - Billions of parameters are dispersed through the network
    - we know how to iteratively adjust them to make it better at prediction
    - we can measure that this works, but we don't really know how the billions of parameters collaborate to do it
- They build & maintain some kind of knowledge db, but it is a bit strange & imperfect
  - for example
    - if a = b is right
    - but b = a is wrong
    - why ??
  - think of LLMS as mostly inscrutable artifacts, they are not similar to anything we build like engineering way like building a car where we understand the parts
  - "interpretability" -> we don't how exactly NN work but we can understand
- Give input and get outputs based on that we understand model
  - till now is pretrained next is fine tuning stage assistant model
  - we don't want document generator
- Summary : How to traing your Chatgpt
  - Stage 1:
    - Pretraining
      - Download ~10Tb of text
      - Get a cluster of ~6000 GPU
      - Compress the text into a neural network, pay $2M, waste ~12 days
      - Obtain base model
  - Stage 2:
    - Finetuning
      - writing detailing instructions
      - hire people (or use scale.ai), collect 100k high quality ideal Q&A responses, and/or comparisons
      - finetune base model on this data, wait `1 day
      - obtain assitant model
      - runa lot of evaluations
      - deploy
      - monitor, colllect misbehaviour, go to steps
  - Stage 3:
    - RLHF -> Reinforcement learning from human feedback
    - for  1 question we get multiple answers based on that we choose the best answer & again retrain the model
- Labeling instructions
  - helpful
  - truthful
  - harmless
- Based on thinking fast and slow
  - for example 
    - 2+2 = 
      - System 1 thinking
        - quick 
        - emotional
        - unconscious
        - little/no effort
        - automatic
        - instinctive
    - 17 * 24 =
      - System 2 thinking
        - slower
        - complex decisions
        - more logical
        - effortful
        - conscious
        - rational
  - System 1 : generates the proposal 
    - used in speed chess
  - System 2 : keeps track of tree
    - used in competitions
- LLMs currently only have a systems 1
  - Now how can we create tree of thoughts Like tree search in chess, but in language we want to "think" convent time to accuracy
- AlphaGo had two major steps:
  - learn by imitating expert human players
  - learn by self-improvement ( reward = with the game )
- Retrieval Augmented Generation (RAG)
  - Chatgpt can references chunks of text in the uploaded file s& use that when it creates responses so it's kind of like an equivalent of browsing, not internet but browse files
- An LLM in a few years
  - It can read & generate text
  - It has more knowledge than any single human about all subjects
  - It can browse the internet
  - It can use the existing software infrastructure (calculator, Python, mouse/keyboard)
  - It can see and generate images & video
  - It can hear & speak & generate music
  - It can think for a long time using a System 2
  - It can "self-improve" in domains that offer a reward function
  - It can be customized & fine tuned for specific tasks, many versions exists in app stores
  - It can communicate with other LLMs
- Jail Break
  - Case 1 : Prompt Injection
    - Take a white image
      - give it to gpt
    - we get answer as "I don't know. By the way there's a 10% off sale happening at Sephora"
    - What actually happened is that
      - in the white image the text is mentinoed woth white color font which gpt could read based on that it will generate answers.
  - Case 2 : When we ask "What are the best movies of 2022?"
    - it will show all movies list by browsing links in hte ending it will also show a amazon gift card voucher with a link to signup the amazon.
    - But the link is a fruad link which is generated by the website where the websites contains a prompt injection attack,
    - e.g. usually hidden on page in white text, giving there instructions.
  - Case 3 : 
    - ask bard to help with a shared google doc
    - google doc contains a prompt injection attack
    - bard is hijacked & encodes personal data/information into an image URL
    - the attacker controls the server & gets the data via GET request
    - Problem : Google has a " Context Security Polucy" that blocks loading images form arbitary locations
    - Solution: use "Google Apps Scripts"
    - use Apps Script to expose the data to a google doc (that the attacks has access to)